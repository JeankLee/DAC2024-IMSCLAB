{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Create Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RRAM_HKU/anaconda3/envs/DAC/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../common\"))\n",
    "\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "# import pynq\n",
    "import dac_sdc\n",
    "from IPython.display import display\n",
    "\n",
    "import onnxruntime as ort\n",
    "import torch\n",
    "from torchvision.ops import nms\n",
    "from PIL import ImageDraw, ImageFont, Image\n",
    "\n",
    "team_name = 'T-IMI'\n",
    "dac_sdc.BATCH_SIZE = 1\n",
    "team = dac_sdc.Team(team_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparing the library and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/RRAM_HKU/anaconda3/envs/DAC/lib/python3.9/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'TensorrtExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "onnx_model_path = \"./darknet.onnx\"\n",
    "# session = ort.InferenceSession(onnx_model_path, providers=['CUDAExecutionProvider'])\n",
    "# session = ort.InferenceSession(onnx_model_path, providers=['CPUExecutionProvider']))\n",
    "session = ort.InferenceSession(onnx_model_path, providers=['TensorrtExecutionProvider'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Python Callback Function and Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [640, 640]\n",
    "num_classes = 7\n",
    "\n",
    "def preprocess_input(image):\n",
    "    image /= 255.0\n",
    "    return image\n",
    "\n",
    "def resize_image(image, size, letterbox_image):\n",
    "    iw, ih  = image.size\n",
    "    w, h    = size\n",
    "    if letterbox_image:\n",
    "        scale   = min(w/iw, h/ih)\n",
    "        nw      = int(iw*scale)\n",
    "        nh      = int(ih*scale)\n",
    "\n",
    "        image   = image.resize((nw,nh), Image.BICUBIC)\n",
    "        new_image = Image.new('RGB', size, (128,128,128))\n",
    "        new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n",
    "    else:\n",
    "        new_image = image.resize((w, h), Image.BICUBIC)\n",
    "    return new_image\n",
    "\n",
    "# Function to preprocess the image (modify as per your model's requirement)\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path)\n",
    "    img  = resize_image(img, (input_shape[1], input_shape[0]), True)\n",
    "    image_data  = np.expand_dims(np.transpose(preprocess_input(np.array(img, dtype='float32')), (2, 0, 1)), 0)\n",
    "    return image_data\n",
    "\n",
    "def dist2bbox(distance, anchor_points, xywh=True, dim=-1):\n",
    "    \"\"\"Transform distance(ltrb) to box(xywh or xyxy).\"\"\"\n",
    "    # 左上右下\n",
    "    lt, rb  = torch.split(distance, 2, dim)\n",
    "    x1y1    = anchor_points - lt\n",
    "    x2y2    = anchor_points + rb\n",
    "    if xywh:\n",
    "        c_xy    = (x1y1 + x2y2) / 2\n",
    "        wh      = x2y2 - x1y1\n",
    "        return torch.cat((c_xy, wh), dim)  # xywh bbox\n",
    "    return torch.cat((x1y1, x2y2), dim)  # xyxy bbox\n",
    "\n",
    "\n",
    "def decode_box(num_classes, input_shape, dbox, cls, anchors, strides):\n",
    "    # dbox, cls, origin_cls, anchors, strides = inputs\n",
    "    dbox = dist2bbox(dbox, anchors.unsqueeze(0), xywh=True, dim=1) * strides\n",
    "    y = torch.cat((dbox, cls.sigmoid()), 1).permute(0, 2, 1)\n",
    "    y[:, :, :4] = y[:, :, :4] / torch.Tensor([input_shape[1], input_shape[0], input_shape[1], input_shape[0]]).to(y.device)\n",
    "    return y\n",
    "\n",
    "def yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape, letterbox_image):\n",
    "    box_yx = box_xy[..., ::-1]\n",
    "    box_hw = box_wh[..., ::-1]\n",
    "    input_shape = np.array(input_shape)\n",
    "    image_shape = np.array(image_shape)\n",
    "\n",
    "    if letterbox_image:\n",
    "        new_shape = np.round(image_shape * np.min(input_shape/image_shape))\n",
    "        offset = (input_shape - new_shape)/2./input_shape\n",
    "        scale = input_shape/new_shape\n",
    "\n",
    "        box_yx = (box_yx - offset) * scale\n",
    "        box_hw *= scale\n",
    "\n",
    "    box_mins = box_yx - (box_hw / 2.)\n",
    "    box_maxes = box_yx + (box_hw / 2.)\n",
    "    boxes = np.concatenate([box_mins[..., 0:1], box_mins[..., 1:2], box_maxes[..., 0:1], box_maxes[..., 1:2]], axis=-1)\n",
    "    boxes *= np.concatenate([image_shape, image_shape], axis=-1)\n",
    "    return boxes\n",
    "\n",
    "def non_max_suppression(prediction, num_classes, input_shape, image_shape, letterbox_image, conf_thres=0.5, nms_thres=0.4):\n",
    "    box_corner = prediction.new(prediction.shape)\n",
    "    box_corner[:, :, 0] = prediction[:, :, 0] - prediction[:, :, 2] / 2\n",
    "    box_corner[:, :, 1] = prediction[:, :, 1] - prediction[:, :, 3] / 2\n",
    "    box_corner[:, :, 2] = prediction[:, :, 0] + prediction[:, :, 2] / 2\n",
    "    box_corner[:, :, 3] = prediction[:, :, 1] + prediction[:, :, 3] / 2\n",
    "    prediction[:, :, :4] = box_corner[:, :, :4]\n",
    "\n",
    "    output = [None for _ in range(len(prediction))]\n",
    "    for i, image_pred in enumerate(prediction):\n",
    "        class_conf, class_pred = torch.max(image_pred[:, 4:4 + num_classes], 1, keepdim=True)\n",
    "        conf_mask = (class_conf[:, 0] >= conf_thres).squeeze()\n",
    "        image_pred = image_pred[conf_mask]\n",
    "        class_conf = class_conf[conf_mask]\n",
    "        class_pred = class_pred[conf_mask]\n",
    "        if not image_pred.size(0):\n",
    "            continue\n",
    "        detections = torch.cat((image_pred[:, :4], class_conf.float(), class_pred.float()), 1)\n",
    "        unique_labels = detections[:, -1].cpu().unique()\n",
    "\n",
    "        if prediction.is_cuda:\n",
    "            unique_labels = unique_labels.cuda()\n",
    "            detections = detections.cuda()\n",
    "\n",
    "        for c in unique_labels:\n",
    "            detections_class = detections[detections[:, -1] == c]\n",
    "            keep = nms(detections_class[:, :4], detections_class[:, 4], nms_thres)\n",
    "            max_detections = detections_class[keep]\n",
    "            output[i] = max_detections if output[i] is None else torch.cat((output[i], max_detections))\n",
    "        \n",
    "        if output[i] is not None:\n",
    "            output[i] = output[i].cpu().numpy()\n",
    "            box_xy, box_wh = (output[i][:, 0:2] + output[i][:, 2:4])/2, output[i][:, 2:4] - output[i][:, 0:2]\n",
    "            output[i][:, :4] = yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape, letterbox_image)\n",
    "    return output\n",
    "\n",
    "def my_callback(rgb_imgs):\n",
    "    preds = {}\n",
    "    type_mapping = {\"0\": 1, \"1\": 2, \"2\": 3, \"3\": 4, \"4\": 5, \"5\": 6, \"6\": 7}\n",
    "    type_mapping_mask = {\"0\": 0, \"1\": 8, \"2\": 9, \"3\": 10}\n",
    "    # for image_path in tqdm(image_paths, desc=\"Processing images\"):\n",
    "    for (img_path, img) in rgb_imgs:\n",
    "        input_image = preprocess_image(img_path)\n",
    "        image = Image.open(img_path)\n",
    "        # Assuming the model takes an input named 'input' and outputs a tensor named 'output'\n",
    "        image_shape = np.array(np.shape(image)[0:2])\n",
    "        outputs = session.run(None, {'input': input_image})\n",
    "        outputs = [torch.tensor(arr) for arr in outputs]\n",
    "        ########################################################mask\n",
    "        fea_img = torch.argmax(outputs[7].long(), 1)\n",
    "        fea_img = fea_img[0, :, :].cpu().detach().numpy()\n",
    "        fea_img = np.array(fea_img)\n",
    "        ########################################################mask\n",
    "        #0是对的，1是对的，6对4，5对3\n",
    "        outputs = decode_box(num_classes, input_shape, outputs[0], outputs[1], outputs[5], outputs[6])\n",
    "        results = non_max_suppression(outputs, num_classes, input_shape, \n",
    "                    image_shape, True, conf_thres = 0.5, nms_thres = 0.3)\n",
    "        pred = []\n",
    "        if results[0] is None:\n",
    "            pred.append({\n",
    "                \"type\": '1',\n",
    "                \"x\": 0,\n",
    "                \"y\": 0,\n",
    "                \"width\": 0,\n",
    "                \"height\": 0\n",
    "            })\n",
    "            preds[img_path.name] = pred\n",
    "        else:\n",
    "            top_label   = np.array(results[0][:, 5], dtype = 'int32')\n",
    "            # top_conf    = results[0][:, 4]\n",
    "            top_boxes   = results[0][:, :4]\n",
    "            pred = []\n",
    "            for idx in range(len(top_label)):\n",
    "                pred.append({\n",
    "                    \"type\": type_mapping[str(int(top_label[idx]))],\n",
    "                    \"x\": int(top_boxes[idx, 0]),\n",
    "                    \"y\": int(top_boxes[idx, 1]),\n",
    "                    \"width\": int((top_boxes[idx, 2] - top_boxes[idx, 0])),\n",
    "                    \"height\": int((top_boxes[idx, 3] - top_boxes[idx, 1]))\n",
    "                })\n",
    "            preds[img_path.name] = pred \n",
    "            \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 starting. 1 images.\n",
      "[0 0 0 1]\n",
      "Batch 1 done. Runtime = 0.16617178916931152 seconds.\n",
      "Batch 2 starting. 1 images.\n",
      "[0 0 0 0 0]\n",
      "Batch 2 done. Runtime = 0.18919801712036133 seconds.\n",
      "Batch 3 starting. 1 images.\n",
      "[0 0 0 0 0 0 0]\n",
      "Batch 3 done. Runtime = 0.1802361011505127 seconds.\n",
      "Batch 4 starting. 1 images.\n",
      "[0]\n",
      "Batch 4 done. Runtime = 0.14208555221557617 seconds.\n",
      "Batch 5 starting. 1 images.\n",
      "[0 0 0 0]\n",
      "Batch 5 done. Runtime = 0.2192220687866211 seconds.\n",
      "Batch 6 starting. 1 images.\n",
      "Batch 6 done. Runtime = 0.20096850395202637 seconds.\n",
      "Batch 7 starting. 1 images.\n",
      "[0 0 0 0 0 0 0 0 0 1]\n",
      "Batch 7 done. Runtime = 0.12569355964660645 seconds.\n",
      "Batch 8 starting. 1 images.\n",
      "[0 0 1]\n",
      "Batch 8 done. Runtime = 0.16391563415527344 seconds.\n",
      "Batch 9 starting. 1 images.\n",
      "[0 1 1 1 5 6]\n",
      "Batch 9 done. Runtime = 0.1315150260925293 seconds.\n",
      "Batch 10 starting. 1 images.\n",
      "[0 0 0 0 0 0 0 0 0 0 0 2 2]\n",
      "Batch 10 done. Runtime = 0.14395999908447266 seconds.\n",
      "Batch 11 starting. 1 images.\n",
      "[0 0 0 0 0]\n",
      "Batch 11 done. Runtime = 0.16844844818115234 seconds.\n",
      "Batch 12 starting. 1 images.\n",
      "[0 0 0 0 0 0 0 0]\n",
      "Batch 12 done. Runtime = 0.19959568977355957 seconds.\n",
      "Batch 13 starting. 1 images.\n",
      "[0 1 1]\n",
      "Batch 13 done. Runtime = 0.11129498481750488 seconds.\n",
      "Batch 14 starting. 1 images.\n",
      "[1]\n",
      "Batch 14 done. Runtime = 0.20561766624450684 seconds.\n",
      "Batch 15 starting. 1 images.\n",
      "[0 1 1]\n",
      "Batch 15 done. Runtime = 0.16426396369934082 seconds.\n",
      "Batch 16 starting. 1 images.\n",
      "[0 0 0 0 0 0 0 1]\n",
      "Batch 16 done. Runtime = 0.17610597610473633 seconds.\n",
      "Batch 17 starting. 1 images.\n",
      "Batch 17 done. Runtime = 0.16497135162353516 seconds.\n",
      "Batch 18 starting. 1 images.\n",
      "[0 0 0]\n",
      "Batch 18 done. Runtime = 0.1516706943511963 seconds.\n",
      "Batch 19 starting. 1 images.\n",
      "[0 0 0 0 0 0 0 0 1]\n",
      "Batch 19 done. Runtime = 0.2468564510345459 seconds.\n",
      "Batch 20 starting. 1 images.\n",
      "Batch 20 done. Runtime = 0.24222850799560547 seconds.\n",
      "Batch 21 starting. 1 images.\n",
      "[0 0 0]\n",
      "Batch 21 done. Runtime = 0.14806509017944336 seconds.\n",
      "Batch 22 starting. 1 images.\n",
      "[0 0 0 1 1 1 1 1 2]\n",
      "Batch 22 done. Runtime = 0.17546772956848145 seconds.\n",
      "Batch 23 starting. 1 images.\n",
      "[0 0 0 0 0 2]\n",
      "Batch 23 done. Runtime = 0.18621087074279785 seconds.\n",
      "Batch 24 starting. 1 images.\n",
      "[0 0 0 0 0]\n",
      "Batch 24 done. Runtime = 0.11929941177368164 seconds.\n",
      "Batch 25 starting. 1 images.\n",
      "[0 0 0 0 0]\n",
      "Batch 25 done. Runtime = 0.17273664474487305 seconds.\n",
      "Batch 26 starting. 1 images.\n",
      "[0 0 0 0 0 0 0 2]\n",
      "Batch 26 done. Runtime = 0.15146875381469727 seconds.\n",
      "Batch 27 starting. 1 images.\n",
      "[0 0 0 0 3 3]\n",
      "Batch 27 done. Runtime = 0.21773433685302734 seconds.\n",
      "Batch 28 starting. 1 images.\n",
      "[0 0 0 1 1 1 1]\n",
      "Batch 28 done. Runtime = 0.17562603950500488 seconds.\n",
      "Batch 29 starting. 1 images.\n",
      "[0 0 0 1 1 1 1 1 2 2 2]\n",
      "Batch 29 done. Runtime = 0.13694095611572266 seconds.\n",
      "Batch 30 starting. 1 images.\n",
      "[0 0]\n",
      "Batch 30 done. Runtime = 0.22821474075317383 seconds.\n",
      "Batch 31 starting. 1 images.\n",
      "[0]\n",
      "Batch 31 done. Runtime = 0.13628721237182617 seconds.\n",
      "Batch 32 starting. 1 images.\n"
     ]
    }
   ],
   "source": [
    "team.run(my_callback, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DAC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
